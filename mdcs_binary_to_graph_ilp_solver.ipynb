{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V6E1",
      "authorship_tag": "ABX9TyMEQ+Dh12x13folq+pJKhys",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoadoan1997/ChatGPT_App/blob/main/mdcs_binary_to_graph_ilp_solver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Required Libraries"
      ],
      "metadata": {
        "id": "DMlb-yCVwTJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pulp"
      ],
      "metadata": {
        "id": "jLxntbg6xYXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # For handling tabular data (DataFrames)\n",
        "import numpy as np  # For numerical operations and arrays\n",
        "import time  # To measure execution time\n",
        "import os  # For interacting with the operating system (e.g., file paths)\n",
        "import networkx as nx  # For working with graphs and networks\n",
        "\n",
        "from itertools import combinations  # To generate combinations of elements\n",
        "\n",
        "# PuLP - Linear Programming library\n",
        "from pulp import *\n",
        "from pulp import LpVariable, LpProblem, LpMinimize, value, LpStatus, LpBinary  # Optimization components"
      ],
      "metadata": {
        "id": "U4yz_M_vvwdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Binary Dataset to Graph Format"
      ],
      "metadata": {
        "id": "b_ssw7gXwRqR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcE3ngm4Se5k",
        "outputId": "e595fb13-4e86-495f-d46f-5d3a6b8aeaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ƒê√£ xu·∫•t file twitterbot_data.txt v√† twitterbot_feature.txt th√†nh c√¥ng.\n",
            "Th·ªùi gian th·ª±c thi: 0.00 gi√¢y\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time() # Start measuring execution time\n",
        "\n",
        "# Load the binary training dataset (each feature is 0 or 1)\n",
        "df = pd.read_csv(\"/content/binary_dataset/your_file.csv\")\n",
        "\n",
        "# Generate feature IDs starting after the last row ID\n",
        "feature_start_id = len(df) + 1\n",
        "feature_ids = {col: idx for idx, col in enumerate(df.columns, start=feature_start_id)}\n",
        "\n",
        "output_lines = []\n",
        "# Iterate through each row and collect feature links for value = 1\n",
        "for idx, row in df.iterrows():\n",
        "    transaction_id = idx + 1\n",
        "    for col, val in row.items():\n",
        "        if val == 1:\n",
        "            feature_id = feature_ids[col]\n",
        "            output_lines.append(f\"{transaction_id} {feature_id}\")\n",
        "\n",
        "# Write the graph edges (transaction‚Äìfeature) to a text file\n",
        "with open(\"/content/graph_dataset/ccfraud_data.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(output_lines))\n",
        "\n",
        "# Write the mapping of feature ID to feature name\n",
        "with open(\"/content/feature_file/ccfraud_feature.txt\", \"w\") as f:\n",
        "    for col, fid in feature_ids.items():\n",
        "        f.write(f\"{fid} {col}\\n\")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(\"File export successful.\")\n",
        "print(f\"Execution time:: {elapsed_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to Convert All Binary CSVs to Graph Format"
      ],
      "metadata": {
        "id": "lc8EBH2Rwwsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üõ†Ô∏è Function to Convert All Binary CSVs to Graph Format\n",
        "def convert_all_binary_csv(input_dir, graph_output_dir, feature_output_dir):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create output directories if they don't exist\n",
        "    os.makedirs(graph_output_dir, exist_ok=True)\n",
        "    os.makedirs(feature_output_dir, exist_ok=True)\n",
        "\n",
        "    # Loop through all CSV files in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\"_train_binary.csv\"):\n",
        "            print(f\"üîÑ Processing: {filename}\")\n",
        "\n",
        "            file_path = os.path.join(input_dir, filename)\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            # Assign feature IDs (starting after number of rows)\n",
        "            feature_start_id = len(df) + 1\n",
        "            feature_ids = {col: idx for idx, col in enumerate(df.columns, start=feature_start_id)}\n",
        "\n",
        "            output_lines = []\n",
        "\n",
        "            # Generate transaction-feature edges where value == 1\n",
        "            for idx, row in df.iterrows():\n",
        "                transaction_id = idx + 1\n",
        "                for col, val in row.items():\n",
        "                    if val == 1:\n",
        "                        feature_id = feature_ids[col]\n",
        "                        output_lines.append(f\"{transaction_id} {feature_id}\")\n",
        "\n",
        "            # Write graph file (edges)\n",
        "            graph_file_path = os.path.join(\n",
        "                graph_output_dir, filename.replace(\"_train_binary.csv\", \"_data.txt\")\n",
        "            )\n",
        "            with open(graph_file_path, \"w\") as f:\n",
        "                f.write(\"\\n\".join(output_lines))\n",
        "\n",
        "            # Write feature mapping file\n",
        "            feature_file_path = os.path.join(\n",
        "                feature_output_dir, filename.replace(\"_train_binary.csv\", \"_feature.txt\")\n",
        "            )\n",
        "            with open(feature_file_path, \"w\") as f:\n",
        "                for col, fid in feature_ids.items():\n",
        "                    f.write(f\"{fid} {col}\\n\")\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\\n‚úÖ Finished processing all datasets. Total time: {elapsed:.2f} seconds.\")"
      ],
      "metadata": {
        "id": "Th8y1u2ibSDW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run: Convert All Binary CSVs to Graph Format (for Google Colab)"
      ],
      "metadata": {
        "id": "4w86eXTZxIZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚ñ∂Ô∏è Run: Convert All Binary CSVs to Graph Format (for Google Colab)\n",
        "\n",
        "# Make sure you've uploaded the folder `binary_dataset` to /content/ in Colab\n",
        "convert_all_binary_csv(\n",
        "    input_dir=\"/content/binary_dataset\", # Folder containing binary CSV files\n",
        "    graph_output_dir=\"/content/graph_dataset\", # Output: graph edge files\n",
        "    feature_output_dir=\"/content/feature_file\" # Output: feature ID mapping files\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eJmePU8bW7w",
        "outputId": "a9548051-7d64-40d4-c2d5-159a020bfa05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ ƒêang x·ª≠ l√Ω: ccfraud_train_binary.csv\n",
            "üîÑ ƒêang x·ª≠ l√Ω: twitterbot_train_binary.csv\n",
            "üîÑ ƒêang x·ª≠ l√Ω: fraudecom_train_binary.csv\n",
            "üîÑ ƒêang x·ª≠ l√Ω: ipblock_train_binary.csv\n",
            "üîÑ ƒêang x·ª≠ l√Ω: fakejob_train_binary.csv\n",
            "üîÑ ƒêang x·ª≠ l√Ω: vehicleloan_train_binary.csv\n",
            "üîÑ ƒêang x·ª≠ l√Ω: malurl_train_binary.csv\n",
            "\n",
            "‚úÖ X·ª≠ l√Ω ho√†n t·∫•t to√†n b·ªô dataset. Th·ªùi gian: 4.85 gi√¢y.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solve Minimum Discriminating Code Set (MDCS) via Integer Linear Programming"
      ],
      "metadata": {
        "id": "JdlySaYCxgK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To read edge-lists stored as txt files\n",
        "def genGraph():\n",
        "    G = nx.Graph()\n",
        "    G = nx.read_edgelist(\"/content/graph_dataset/your_file.txt\", nodetype=int)\n",
        "    return G\n",
        "\n",
        "\n",
        "# This function computes the optimal MDCS for the input graph\n",
        "def model():\n",
        "    # Inputs the total number of nodes in the graph\n",
        "    numNodes = int(input(\"Enter the number of nodes: \"))\n",
        "\n",
        "    # Inputs the nodes to be uniquely monitored in the graph\n",
        "    transformers = int(input(\"Enter the number of transformers: \"))\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Prepare node groups\n",
        "    nodes = [i + 1 for i in range(transformers, numNodes)] # Nodes to be uniquely monitored\n",
        "    tnodes = [i + 1 for i in range(transformers)]          # Remaining nodes (can be selected as resources)\n",
        "    totNodes = tnodes + nodes\n",
        "\n",
        "    G = genGraph()\n",
        "    G.add_nodes_from(totNodes) # Add all possible nodes to the graph\n",
        "\n",
        "    print(\"Initializing Integer Linear Program\")\n",
        "    print(\"-----------------------------------\")\n",
        "    problem = LpProblem(\"IdentifyingCodes1\", LpMinimize)\n",
        "\n",
        "    # Create binary variables x_i for each node\n",
        "    x = LpVariable.dict(\"x_%s\", totNodes, 0, 1, LpBinary)\n",
        "\n",
        "    # Objective: minimize the number of resource nodes used\n",
        "    problem += sum(x[i] for i in nodes)\n",
        "\n",
        "    # Coloring Constraint: every monitored node must be covered by at least one neighbor\n",
        "    print(\"Adding Coloring Constraints\")\n",
        "    print(\"-----------------------------------\")\n",
        "    for i in tnodes:\n",
        "        valColor = 0 # Initialize valColor outside the inner loop\n",
        "        neighbor = list(G.neighbors(i))\n",
        "        #print(i)\n",
        "        #print(list(G.neighbors(i)))\n",
        "        #print(neighbor)\n",
        "        for j in neighbor:\n",
        "            valColor += x[j]\n",
        "        # Ensure the constraint is valid before adding\n",
        "        if valColor >= 1:\n",
        "            problem += valColor >= 1, \"Coloring_Constraint_{}\".format(i)\n",
        "    valUnique = 0 # Initialize valUnique outside the inner loop\n",
        "    neighbor_i = []\n",
        "    neighbor_j = []\n",
        "\n",
        "    # Uniqueness Constraint: each pair of monitored nodes must have different monitoring sets\n",
        "    print(\"Adding Uniqueness Constraints\")\n",
        "    print(\"-----------------------------------\")\n",
        "    comb = combinations(tnodes, 2)\n",
        "    for i in comb:\n",
        "        pair = list(i)\n",
        "        #print(pair)\n",
        "        node1 = pair[0]\n",
        "        node2 = pair[1]\n",
        "        neighbor1 = list(G.neighbors(node1))\n",
        "        neighbor2 = list(G.neighbors(node2))\n",
        "        set1 = set(neighbor1)\n",
        "        set2 = set(neighbor2)\n",
        "        unique = list(set1.symmetric_difference(set2))\n",
        "        #print(unique)\n",
        "        valUnique = 0 # Initialize valUnique for each pair of nodes\n",
        "        for k in unique:\n",
        "            valUnique += x[k]\n",
        "        # Ensure the constraint is valid before adding\n",
        "        if valUnique >= 1:\n",
        "            problem += valUnique >= 1, \"Uniqueness_Constraint_{}\".format(i)\n",
        "\n",
        "    # Solve the ILP\n",
        "    print(\"Solving\")\n",
        "    print(\"-------------------------------------------------------\")\n",
        "    problem.solve()\n",
        "\n",
        "    # Output solution\n",
        "    if LpStatus[problem.status] == 'Optimal':\n",
        "        for v in problem.variables():\n",
        "            print(v.name, \"=\", v.varValue)\n",
        "    #for k, v in problem.constraints.items():\n",
        "        #print(k, v)\n",
        "\n",
        "    print(\"-------------------------------------------------------\")\n",
        "    print(\"Amount of Resources Required for Unique Monitoring: {}\".format(value(problem.objective)))\n",
        "    print(\"Total Number of Nodes to be Uniquely Monitored: {}\".format(len(tnodes)))\n",
        "    print(\"% Savings: {}\".format(float(100 * (len(tnodes) - int(value(problem.objective))) / len(tnodes))))\n",
        "    print(\"-------------------------------------------------------\")\n",
        "    print(\"Time taken = {} seconds\".format(time.time() - start))\n",
        "    print(\"-------------------------------------------------------\")\n",
        "    #print(G.number_of_edges())\n",
        "\n",
        "# Entry point\n",
        "def main():\n",
        "    model()\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "1YpqZ1BxVS-1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}